#!/usr/bin/env python3
"""
Script to check and diagnose model file issues
"""
import os
import torch
from pathlib import Path

def check_model_file(model_path):
    """Check if model file is valid"""
    print("=" * 60)
    print("Model File Diagnostic Tool")
    print("=" * 60)
    print()
    
    # Check if file exists
    if not os.path.exists(model_path):
        print(f"‚ùå ERROR: Model file not found at {model_path}")
        return False
    
    # Check file size
    file_size = os.path.getsize(model_path)
    file_size_mb = file_size / (1024 * 1024)
    print(f"‚úì File exists: {model_path}")
    print(f"‚úì File size: {file_size_mb:.2f} MB ({file_size:,} bytes)")
    
    # Check if it's a zip file
    try:
        import zipfile
        if zipfile.is_zipfile(model_path):
            print("‚úì File is a valid ZIP archive")
        else:
            print("‚ö† WARNING: File is not a valid ZIP archive")
    except Exception as e:
        print(f"‚ö† Could not verify ZIP format: {e}")
    
    # Try to load the model
    print("\nAttempting to load model...")
    try:
        # Try loading on CPU first
        loaded_data = torch.load(model_path, map_location='cpu', weights_only=False)
        print("‚úì Model loaded successfully!")
        
        # Check what type of data was loaded
        if isinstance(loaded_data, dict):
            print(f"‚úì Loaded data type: dict (state_dict)")
            print(f"‚úì Number of keys: {len(loaded_data)}")
            if len(loaded_data) > 0:
                print(f"‚úì Sample keys: {list(loaded_data.keys())[:5]}")
                # Check sizes of first few tensors
                for i, (key, value) in enumerate(list(loaded_data.items())[:3]):
                    if hasattr(value, 'shape'):
                        print(f"  - {key}: shape {value.shape}, dtype {value.dtype}")
        elif hasattr(loaded_data, 'state_dict'):
            print(f"‚úì Loaded data type: Model object (has state_dict method)")
        else:
            print(f"‚ö† Loaded data type: {type(loaded_data)}")
        
        # Try to load into a model architecture
        print("\nAttempting to load into model architecture...")
        try:
            import torch.nn as nn
            import torchvision.models as models
            
            # Recreate model architecture
            try:
                vgg16 = models.vgg16(weights=None)
            except (TypeError, AttributeError):
                vgg16 = models.vgg16(pretrained=False)
            
            features = nn.Sequential(*list(vgg16.features.children()))
            classifier = nn.Sequential(
                nn.AdaptiveAvgPool2d((7, 7)),
                nn.Flatten(),
                nn.Linear(512 * 7 * 7, 4096),
                nn.ReLU(True),
                nn.Dropout(0.5),
                nn.Linear(4096, 4096),
                nn.ReLU(True),
                nn.Dropout(0.5),
                nn.Linear(4096, 2)
            )
            model = nn.Sequential(features, classifier)
            
            # Try to load state dict
            if isinstance(loaded_data, dict):
                model.load_state_dict(loaded_data)
            elif hasattr(loaded_data, 'state_dict'):
                model.load_state_dict(loaded_data.state_dict())
            else:
                model.load_state_dict(loaded_data)
            
            print("‚úì Successfully loaded into model architecture!")
            print("‚úì Model is ready to use!")
            return True
            
        except Exception as arch_error:
            print(f"‚ùå ERROR: Failed to load into model architecture")
            print(f"   Error: {str(arch_error)}")
            return False
        
    except RuntimeError as e:
        error_msg = str(e)
        if "corrupted" in error_msg.lower() or "invalid header" in error_msg.lower():
            print(f"‚ùå ERROR: Model file appears to be CORRUPTED")
            print(f"   Error: {error_msg}")
            print("\nüí° SOLUTION: The model file is corrupted. You need to retrain:")
            print("   1. Delete the corrupted model: rm artifacts/training/model.pth")
            print("   2. Retrain the model: python main.py")
            return False
        else:
            print(f"‚ùå ERROR: Failed to load model")
            print(f"   Error: {error_msg}")
            return False
    except Exception as e:
        print(f"‚ùå ERROR: Unexpected error")
        print(f"   Error type: {type(e).__name__}")
        print(f"   Error message: {str(e)}")
        return False
    
    print("\n" + "=" * 60)
    return True

if __name__ == "__main__":
    model_path = "artifacts/training/model.pth"
    
    if check_model_file(model_path):
        print("\n‚úÖ Model file is valid and ready to use!")
    else:
        print("\n‚ùå Model file has issues. Please retrain the model.")
        print("\nTo retrain:")
        print("  python main.py")

